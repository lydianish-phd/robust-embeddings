#!/bin/bash

#SBATCH --job-name=train      # Job name
#SBATCH --nodes=1                # node count
#SBATCH --ntasks-per-node=2               # total number of tasks across all nodes
#SBATCH --partition=gpu          # Name of the partition
##SBATCH --account=almanach        # GPU nodes are only available in gpu partition
#SBATCH --gres=gpu:rtx8000:2        # GPU nodes are only available in gpu partition
#SBATCH --cpus-per-task=2
#SBATCH --hint=nomultithread       # we get physical cores not logical
#SBATCH --time=00:10:00                # Time limit hrs:min:sec
#SBATCH --output=/scratch/lnishimw/logs/robust-embeddings/sonar/%x/%x_%j.log # Standard output and error log

echo "### Running $SLURM_JOB_NAME ###"

module purge
module load cuda/10.2

source $HOME/.bashrc 
source $HOME/.bash_profile
source activate sonar_env

set -e

TEACHER_MODEL=$LASER/models/laser2.pt
STUDENT_MODEL=$MODELS/roberta-base/pytorch_model.bin
EXPERIMENT_DIR=$EXPERIMENTS/robust-embeddings/laser/experiment_035
OUTPUT_DIR=$EXPERIMENT_DIR/models
TENSORBOARD_DIR=$EXPERIMENT_DIR/tensorboard
CONFIG_PATH=$EXPERIMENT_DIR/train-config.json

echo "Training student model $SLURM_ARRAY_TASK_ID..."

accelerate launch $HOME/robust-embeddings/src/sonar/train.py

echo "Done..."

