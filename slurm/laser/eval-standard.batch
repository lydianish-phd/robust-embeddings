#!/bin/bash

#SBATCH --job-name=eval-standard      # Job name
#SBATCH --ntasks=1                    # A single task (process)
#SBATCH --nodes=1                # node count
#SBATCH --partition=almanach          # Name of the partition
#SBATCH --account=almanach          # Name of the partition
#SBATCH --gres=gpu:rtx8000:1        # GPU nodes are only available in gpu partition
#SBATCH --cpus-per-task=32              # Using 32 CPUS
#SBATCH --hint=nomultithread
#SBATCH --time=24:00:00               # Time limit hrs:min:sec
#SBATCH --output=/scratch/lnishimw/logs/robust-embeddings/laser/eval/eval_%j.log # Standard output and error log
#SBATCH --array=0

set -e 

echo "### Running $SLURM_JOB_NAME $SLURM_ARRAY_TASK_ID ###"

source $HOME/.bashrc
source $HOME/.bash_profile
source activate laser_env

MODEL_NAME[0]=laser
MODEL_PATH[0]=$LASER/models/laser2.pt
VOCAB_FILE[0]=$LASER/models/laser2.cvocab
TOKENIZER_PATH[0]=$HOME/data-preparation/src/spm-tokenizer.sh

BACKBONE_MODEL=roberta-base
MODEL_NAME[1]=roberta-student
MODEL_PATH[1]=$EXPERIMENTS/robust-embeddings/laser/experiment_024_jz/checkpoints/${MODEL_NAME[1]}/checkpoint_best.pt
VOCAB_FILE[1]=$MODELS/checkpoints/$BACKBONE_MODEL/$BACKBONE_MODEL.cvocab
TOKENIZER_PATH[1]=$HOME/data-preparation/src/roberta-tokenizer.sh

MODEL_NAME[2]=roberta-student-init
MODEL_PATH[2]=$EXPERIMENTS/robust-embeddings/laser/experiment_024_jz/checkpoints/${MODEL_NAME[2]}/checkpoint_best.pt
VOCAB_FILE[2]=$MODELS/checkpoints/$BACKBONE_MODEL/$BACKBONE_MODEL.cvocab
TOKENIZER_PATH[2]=$HOME/data-preparation/src/roberta-tokenizer.sh

MODEL_NAME[3]=character-roberta-student
MODEL_PATH[3]=$EXPERIMENTS/robust-embeddings/laser/experiment_024_jz/checkpoints/${MODEL_NAME[3]}/checkpoint_best.pt
VOCAB_FILE[3]=$DATASETS/oscar/mini/4M/bin/charobertaugc-charobertastd/dict.charobertaugc.txt
TOKENIZER_PATH[3]=$HOME/data-preparation/src/char-tokenizer.sh

MODEL_NAME[4]=character-roberta-student-init
MODEL_PATH[4]=$EXPERIMENTS/robust-embeddings/laser/experiment_024_jz/checkpoints/${MODEL_NAME[4]}/checkpoint_best.pt
VOCAB_FILE[4]=$DATASETS/oscar/mini/4M/bin/charobertaugc-charobertastd/dict.charobertaugc.txt
TOKENIZER_PATH[4]=$HOME/data-preparation/src/char-tokenizer.sh

METRIC=xsim

#------------------ FLORES ------------------#

NOISY_LANGS=cleaned.eng_Latn.copy
TARGET_LANG=cleaned.eng_Latn
EXPERIMENT_DIR=$EXPERIMENTS/robust-embeddings/laser/experiment_025_lrec_$METRIC
INPUT_DIR=$DATASETS
CORPUS=flores200
CORPUS_PARTS="dev devtest"

#------- MULTILEXNORM ------------------#

# NOISY_LANGS=cleaned.en.ref.copy
# TARGET_LANG=cleaned.en.ref
# EXPERIMENT_DIR=$EXPERIMENTS/robust-embeddings/laser/experiment_025_lrec_$METRIC
# INPUT_DIR=$DATASETS
# CORPUS=multilexnorm2021
# CORPUS_PARTS="train dev test"

#------------------ ROCSMT ------------------#

# NOISY_LANGS=cleaned.src.norm-manseg.en.copy
# TARGET_LANG=cleaned.src.norm-manseg.en
# EXPERIMENT_DIR=$EXPERIMENTS/robust-embeddings/laser/experiment_025_lrec_$METRIC
# INPUT_DIR=$DATASETS
# CORPUS=rocsmt
# CORPUS_PARTS="test"

for CORPUS_PART in $CORPUS_PARTS
do
    OUTPUT_DIR=$EXPERIMENT_DIR/scores/${MODEL_NAME[$SLURM_ARRAY_TASK_ID]}/$CORPUS/standard/$CORPUS_PART
    mkdir -p $OUTPUT_DIR

    echo "$CORPUS_PART"
    
    echo " - calculating xsim and cos dist"

    python3 $LASER/source/eval.py                \
        --base-dir $INPUT_DIR                         \
        --corpus $CORPUS/standard                        \
        --corpus-part $CORPUS_PART               \
        --margin ratio                           \
        --src-encoder ${MODEL_PATH[$SLURM_ARRAY_TASK_ID]}  \
        --src-tokenizer ${TOKENIZER_PATH[$SLURM_ARRAY_TASK_ID]}  \
        --src-vocab-file ${VOCAB_FILE[$SLURM_ARRAY_TASK_ID]} \
        --tgt-encoder ${MODEL_PATH[0]}  \
        --tgt-tokenizer ${TOKENIZER_PATH[0]}  \
        --tgt-vocab-file ${VOCAB_FILE[0]} \
        --src-langs $NOISY_LANGS      \
        --tgt-langs $TARGET_LANG \
        --output-dir $OUTPUT_DIR \
        --cosine-distances \
        --verbose 
    
    if [ "$CORPUS" == "flores200" ]
    then
        echo " - calculating xsim++"

        python3 $LASER/source/eval.py                \
            --base-dir $INPUT_DIR                         \
            --corpus $CORPUS/standard                         \
            --corpus-part $CORPUS_PART               \
            --margin ratio                           \
            --src-encoder ${MODEL_PATH[$SLURM_ARRAY_TASK_ID]}  \
            --src-tokenizer ${TOKENIZER_PATH[$SLURM_ARRAY_TASK_ID]}  \
            --src-vocab-file ${VOCAB_FILE[$SLURM_ARRAY_TASK_ID]} \
            --tgt-encoder ${MODEL_PATH[0]}  \
            --tgt-tokenizer ${TOKENIZER_PATH[0]}  \
            --tgt-vocab-file ${VOCAB_FILE[0]} \
            --src-langs $NOISY_LANGS      \
            --tgt-langs $TARGET_LANG \
            --tgt-aug-langs $TARGET_LANG \
            --output-dir $OUTPUT_DIR \
            --verbose 
    fi
done

echo "Done..."