#!/bin/bash

#SBATCH --job-name=mteb      # Job name
#SBATCH --nodes=1                # node count
#SBATCH --ntasks=1               # total number of tasks across all nodes
#SBATCH --partition=gpu          # Name of the partition
#SBATCH --gres=gpu:rtx8000:1        # GPU nodes are only available in gpu partition
#SBATCH --hint=nomultithread       # we get physical cores not logical
#SBATCH --time=48:00:00                # Time limit hrs:min:sec
#SBATCH --output=/scratch/lnishimw/logs/robust-embeddings/laser/%x/%x%j.log # Standard output and error log
##SBATCH --array=0,1,3

echo "### Running $SLURM_JOB_NAME ###"

module purge
module load cuda/10.2

source $HOME/.bashrc 
source $HOME/.bash_profile
source activate laser_env

set -e

# to be able to use fairseq files
FAIRSEQ_PATH=$SCRATCH/fairseq/
export PYTHONPATH=$PYTHONPATH:$FAIRSEQ_PATH

# to be able to use LASER files
LASER_PATH=$LASER/source/
export PYTHONPATH=$PYTHONPATH:$LASER_PATH

LASER_EXPERIMENTS_DIR=$EXPERIMENTS/robust-embeddings/laser
CHECKPOINT_DIR=$LASER_EXPERIMENTS_DIR/experiment_024_jz

MODEL_NAME[0]=laser
MODEL_PATH[0]=$LASER/models/laser2.pt
VOCAB_PATH[0]=$LASER/models/laser2.cvocab
TOKENIZER[0]=spm

BACKBONE_MODEL=roberta-base
MODEL_NAME[1]=roberta-student
MODEL_PATH[1]=$CHECKPOINT_DIR/checkpoints/${MODEL_NAME[1]}/checkpoint_best.pt
VOCAB_PATH[1]=$MODELS/checkpoints/$BACKBONE_MODEL/$BACKBONE_MODEL.cvocab
TOKENIZER[1]=roberta

MODEL_NAME[2]=roberta-student-init
MODEL_PATH[2]=$CHECKPOINT_DIR/checkpoints/${MODEL_NAME[2]}/checkpoint_best.pt
VOCAB_PATH[2]=$MODELS/checkpoints/$BACKBONE_MODEL/$BACKBONE_MODEL.cvocab
TOKENIZER[2]=roberta

MODEL_NAME[3]=character-roberta-student
MODEL_PATH[3]=$CHECKPOINT_DIR/checkpoints/${MODEL_NAME[3]}/checkpoint_best.pt
VOCAB_PATH[3]=$DATASETS/oscar/mini/4M/bin/charobertaugc-charobertastd/dict.charobertaugc.txt
TOKENIZER[3]=char

MODEL_NAME[4]=character-roberta-student-init
MODEL_PATH[4]=$CHECKPOINT_DIR/checkpoints/${MODEL_NAME[4]}/checkpoint_best.pt
VOCAB_PATH[4]=$DATASETS/oscar/mini/4M/bin/charobertaugc-charobertastd/dict.charobertaugc.txt
TOKENIZER[4]=char

OUTPUT_DIR=$LASER_EXPERIMENTS_DIR/experiment_025_mteb/scores/${MODEL_NAME[$SLURM_ARRAY_TASK_ID]}

python $LASER/source/mteb_tasks.py \
    --encoder ${MODEL_PATH[$SLURM_ARRAY_TASK_ID]} \
    --vocab ${VOCAB_PATH[$SLURM_ARRAY_TASK_ID]} \
    --tokenizer ${TOKENIZER[$SLURM_ARRAY_TASK_ID]} \
    --output-dir $OUTPUT_DIR \
    --verbose \
    --english-only 
